{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM Health Phenotype Discovery - Presentation Materials\n\n",
    "## MSc Public Health Data Science - SDS6217 Advanced Machine Learning\n\n",
    "---\n\n",
    "**Group 6 Members:**\n\n",
    "| Student ID            | Student Name          |\n",
    "|-----------------------|-----------------------|\n",
    "| SDS6/46982/2024       | Cavin Otieno          |\n",
    "| SDS6/46284/2024       | Joseph Ongoro Marindi |\n",
    "| SDS6/47543/2024       | Laura Nabalayo Kundu  |\n",
    "| SDS6/47545/2024       | Nevin Khaemba         |\n\n",
    "---\n\n",
    "**Date:** January 2025  \n",
    "**Institution:** University of Nairobi  \n\n",
    "---\n\n",
    "### Document Overview\n\n",
    "This document provides comprehensive presentation materials for the GMM Health Phenotype Discovery project, including:\n\n",
    "1. **Cell Numbering Guide** - Consistent phase numbering for the notebook\n",
    "2. **Markdown Explanations** - Added explanations for all code cells\n",
    "3. **Technical Glossary** - Definitions of all ML terms used\n",
    "4. **Output Analysis** - Detailed analysis of all generated plots and metrics\n",
    "5. **Performance Critique** - Critical evaluation of model performance\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Notebook Structure and Cell Numbering Guide\n\n",
    "The following shows the recommended structure for the presentation notebook with consistent phase numbering:\n\n",
    "| Cell # | Type | Content | Purpose |\n",
    "|--------|------|---------|---------|\n",
    "| 1 | Markdown | Title & Overview | Project introduction |\n",
    "| 2 | Markdown | Phase 1: Library Imports | Imports explanation |\n",
    "| 3 | Code | Phase 1: Imports | Execute imports |\n",
    "| 4 | Markdown | Phase 2: Configuration | Configuration explanation |\n",
    "| 5 | Code | Phase 2: Configuration | Setup paths and utilities |\n",
    "| 6 | Code | Project Phases Overview | Display workflow |\n",
    "| 7 | Code | Variable Definitions | Clinical context |\n",
    "| 8 | Markdown | Phase 3: EDA | EDA explanation |\n",
    "| 9 | Code | Phase 3: EDA | Statistical summaries |\n",
    "| 10 | Code | Phase 3: Correlation Analysis | Correlation heatmap |\n",
    "| 11 | Code | Phase 3: Missing Value Analysis | Missing data visualization |\n",
    "| 12 | Markdown | Phase 4: Preprocessing | Preprocessing explanation |\n",
    "| 13 | Code | Phase 4: Preprocessing | Handle missing values |\n",
    "| 14 | Code | Phase 4: Feature Selection | Select features for GMM |\n",
    "| 15 | Code | Phase 4: Feature Engineering | Create derived variables |\n",
    "| 16 | Code | Phase 4: Data Scaling | Standardize features |\n",
    "| 17 | Markdown | Phase 5: Dimensionality Reduction | PCA/t-SNE explanation |\n",
    "| 18 | Code | Phase 5: PCA | Principal Component Analysis |\n",
    "| 19 | Code | Phase 5: t-SNE | t-SNE visualization |\n",
    "| 20 | Markdown | Phase 6: Hyperparameter Tuning | BIC/AIC explanation |\n",
    "| 21 | Code | Phase 6: BIC/AIC Analysis | Model selection |\n",
    "| 22 | Code | Phase 6: Grid Search | Hyperparameter optimization |\n",
    "| 23 | Code | Phase 6: Model Comparison | Compare configurations |\n",
    "| 24 | Markdown | Phase 7: Train Model | GMM training explanation |\n",
    "| 25 | Code | Phase 7: Train Optimal GMM | Fit final model |\n",
    "| 26 | Markdown | Phase 8: Cluster Interpretation | Profiling explanation |\n",
    "| 27 | Code | Phase 8: Cluster Profiles | Analyze cluster characteristics |\n",
    "| 28 | Markdown | Phase 9: Visualization | Visualization explanation |\n",
    "| 29 | Code | Phase 9: Cluster Visualization | 2D/3D plots |\n",
    "| 30 | Markdown | Phase 10: Model Evaluation | Metrics explanation |\n",
    "| 31 | Code | Phase 10: Evaluation Metrics | Compute quality metrics |\n",
    "| 32 | Code | Phase 10: Comprehensive Evaluation | Full evaluation report |\n",
    "| 33 | Markdown | Phase 11: Probabilistic Membership | Probability explanation |\n",
    "| 34 | Code | Phase 11: Membership Analysis | Analyze probabilities |\n",
    "| 35 | Markdown | Phase 12: Medical History | Clinical validation |\n",
    "| 36 | Code | Phase 12: Medical History Analysis | Disease prevalence by cluster |\n",
    "| 37 | Markdown | Phase 13: Statistical Validation | Statistical testing |\n",
    "| 38 | Code | Phase 13: Cluster Validation | ANOVA and chi-square |\n",
    "| 39 | Markdown | Phase 14: Feature Importance | Feature contribution |\n",
    "| 40 | Code | Phase 14: Feature Importance | Identify key features |\n",
    "| 41 | Markdown | Phase 15: Uncertainty Analysis | Probability distributions |\n",
    "| 42 | Code | Phase 15: Uncertainty Analysis | Assignment certainty |\n",
    "| 43 | Markdown | Phase 16: Feature Distributions | Box/violin plots |\n",
    "| 44 | Code | Phase 16: Feature Boxplots | Distribution by cluster |\n",
    "| 45 | Code | Phase 16: Feature Violin Plots | Density visualization |\n",
    "| 46 | Markdown | Phase 17: Probability Uncertainty | Confidence visualization |\n",
    "| 47 | Code | Phase 17: Probability Visualization | Detailed probability plots |\n",
    "| 48 | Markdown | Phase 18: Cluster Distribution | Size analysis |\n",
    "| 49 | Code | Phase 18: Cluster Size Analysis | Proportion analysis |\n",
    "| 50 | Markdown | Phase 19: Demographics | Population characteristics |\n",
    "| 51 | Code | Phase 19: Demographics Analysis | Chi-square tests |\n",
    "| 52 | Markdown | Phase 20: Final Summary | Summary and export |\n",
    "| 53 | Code | Phase 20: Complete Export | Final results |\n",
    "| 54 | Markdown | Phase 21: References | Academic citations |\n\n",
    "**Total: 54 cells (21 phases × 2-3 cells per phase)**\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Technical Glossary - Machine Learning Terms\n\n",
    "### Core GMM Terms\n\n",
    "**Gaussian Mixture Model (GMM)**  \n",
    "A probabilistic model that assumes all data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. Each cluster is modeled as a Gaussian distribution, and each data point belongs to each cluster with a certain probability. Unlike K-means which performs hard clustering, GMM provides soft clustering with probability estimates for each assignment.\n\n",
    "**Components (K)**  \n",
    "The number of Gaussian distributions (clusters) in the mixture model. This is the primary hyperparameter that needs to be determined during model selection. Too few components may underfit the data, while too many may overfit.\n\n",
    "**Covariance Matrix**  \n",
    "A matrix that describes the variance of each feature and the covariance between features within a cluster. The covariance type determines the structure of this matrix:\n",
    "- **Full**: Each cluster has its own general covariance matrix\n",
    "- **Tied**: All clusters share the same covariance matrix\n",
    "- **Diagonal**: Each cluster has its own diagonal covariance matrix\n",
    "- **Spherical**: Each cluster has a single variance value\n\n",
    "**Mean (μ)**  \n",
    "The center or centroid of a Gaussian component. In GMM, each cluster has a mean vector representing the average feature values for that cluster.\n\n",
    "**Weight (π)**  \n",
    "The mixing coefficient that represents the proportion of data points belonging to each Gaussian component. Weights must sum to 1 across all components.\n\n",
    "**EM Algorithm (Expectation-Maximization)**  \n",
    "The iterative algorithm used to fit GMM parameters. The E-step computes the probability of each point belonging to each cluster (responsibilities), and the M-step updates the parameters (means, covariances, weights) to maximize the likelihood given the responsibilities.\n\n",
    "**Responsibilities**  \n",
    "The posterior probability that a data point belongs to each cluster, computed in the E-step. These indicate how confident the model is about each assignment.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection Criteria\n\n",
    "**BIC (Bayesian Information Criterion)**  \n",
    "A criterion for model selection that balances model fit (log-likelihood) against model complexity (number of parameters). Lower BIC values indicate better models. BIC penalizes complexity more heavily than AIC, making it more conservative. Formula: BIC = -2 × log(L) + k × log(n), where L is likelihood, k is parameters, and n is sample size.\n\n",
    "**AIC (Akaike Information Criterion)**  \n",
    "An information-theoretic criterion that estimates the relative quality of models by balancing fit and complexity. Lower AIC values indicate better models. Formula: AIC = -2 × log(L) + 2k. AIC is less conservative than BIC and may select models with more components.\n\n",
    "**Log-Likelihood**  \n",
    "The logarithm of the likelihood function evaluated at the estimated parameters. Higher log-likelihood indicates better model fit to the data. However, more complex models will always have higher log-likelihood, which is why BIC and AIC are used for comparison.\n\n",
    "**Number of Parameters**  \n",
    "For GMM with n features and k components:\n",
    "- Full covariance: k × (n × (n+1)/2 + n + 1) - 1 parameters\n",
    "- Diagonal covariance: k × (2n + 1) - 1 parameters\n",
    "- Spherical covariance: k × 2 - 1 parameters\n\n",
    "This is used in BIC/AIC calculations to penalize model complexity.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Quality Metrics\n\n",
    "**Silhouette Score**  \n",
    "A measure of how similar a point is to its own cluster compared to other clusters. Ranges from -1 to +1, where higher values indicate better-defined clusters. Silhouette = (b - a) / max(a, b), where a is mean intra-cluster distance and b is mean nearest-cluster distance.\n\n",
    "**Calinski-Harabasz Index (Variance Ratio Criterion)**  \n",
    "The ratio of between-cluster dispersion to within-cluster dispersion. Higher values indicate better-defined clusters. CH = (SSB / (k-1)) / (SSW / (n-k)), where SSB is between-cluster sum of squares and SSW is within-cluster sum of squares.\n\n",
    "**Davies-Bouldin Index**  \n",
    "A measure of the average similarity between each cluster and its most similar cluster. Lower values indicate better clustering (less similarity between clusters). DB = (1/k) × Σ max((σi + σj) / d(ci, cj)) for i ≠ j, where σi is the average distance from points in cluster i to centroid ci, and d(ci, cj) is distance between centroids.\n\n",
    "**Entropy**  \n",
    "A measure of uncertainty in cluster assignments. For GMM, entropy is calculated from the probability distribution: H = -Σ p(i) × log(p(i)). Lower entropy indicates more certain assignments, while higher entropy suggests overlapping clusters.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction Terms\n\n",
    "**PCA (Principal Component Analysis)**  \n",
    "A linear dimensionality reduction technique that finds the directions of maximum variance in high-dimensional data. The first principal component captures the most variance, the second captures the second-most, and so on. PCA transforms the data into a new coordinate system where the greatest variance comes to lie on the first coordinate.\n\n",
    "**Explained Variance Ratio**  \n",
    "The proportion of total variance explained by each principal component. This indicates how much information is retained when reducing dimensions. The cumulative explained variance ratio helps determine the number of components needed.\n\n",
    "**t-SNE (t-Distributed Stochastic Neighbor Embedding)**  \n",
    "A non-linear dimensionality reduction technique particularly well-suited for visualizing high-dimensional data in 2D or 3D. t-SNE converts similarities between data points to joint probabilities and minimizes the Kullback-Leibler divergence between joint probabilities in the original and embedded space.\n\n",
    "**Perplexity**  \n",
    "A parameter in t-SNE that approximates the number of effective nearest neighbors. Typical values range from 5 to 50. Higher perplexity considers more global structure, while lower values focus on local neighborhood.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Terms\n\n",
    "**ANOVA (Analysis of Variance)**  \n",
    "A statistical method used to test differences between two or more means. In clustering, ANOVA tests whether the means of a continuous variable differ significantly across clusters, validating that clusters represent genuinely different groups.\n\n",
    "**F-statistic**  \n",
    "The ratio of between-group variance to within-group variance in ANOVA. Higher F-values indicate greater differences between cluster means relative to within-cluster variance.\n",
    "**p-value**  \n",
    "The probability of observing results at least as extreme as the measured results, assuming the null hypothesis is true. In clustering, p < 0.05 typically indicates statistically significant differences between clusters.\n\n",
    "**Chi-Square Test**  \n",
    "A statistical test used to determine if there is a significant association between two categorical variables. In clustering, it tests whether cluster membership is independent of demographic or categorical variables.\n\n",
    "**Chi-Square Statistic (χ²)**  \n",
    "A measure of the discrepancy between observed and expected frequencies. Higher values indicate stronger association between variables.\n\n",
    "**Degrees of Freedom**  \n",
    "The number of independent pieces of information available for estimating parameters. For chi-square: df = (r-1) × (c-1) where r and c are the numbers of rows and columns in the contingency table.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Output Analysis and Plot Interpretations\n\n",
    "### Phase 3: Exploratory Data Analysis Outputs\n\n",
    "#### Distribution Plots (01_health_indicator_distributions.png)\n\n",
    "**What it shows:** Histograms of key health indicators (BMI, blood pressure, cholesterol, glucose, age, PHQ-9 score) with mean and median lines overlaid.\n\n",
    "**How to interpret:** \n",
    "- **Skewness**: If mean > median, distribution is right-skewed (positive skew). Many health indicators (like BMI, glucose) typically show right skew.\n",
    "- **Outliers**: Points far from the main distribution may indicate measurement errors or extreme cases.\n",
    "- **Multi-modality**: Multiple peaks may suggest natural subgroups in the population.\n",
    "- **Clinical thresholds**: Red vertical lines can show clinical cutoffs (e.g., BMI > 30 for obesity).\n\n",
    "**Key findings to report:**\n",
    "- Population mean BMI and comparison to clinical categories\n",
    "- Distribution shape of blood pressure (normotensive vs hypertensive patterns)\n",
    "- Glucose distribution and potential diabetic/prediabetic subpopulations\n",
    "- Age distribution of the sample\n\n",
    "**Presentation talking points:**\n",
    "\"The distribution analysis reveals right-skewed patterns in BMI and glucose, consistent with the known epidemiology of metabolic disorders in the US population. The presence of multiple peaks in some variables suggests natural population heterogeneity that GMM can capture.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Heatmap (02_correlation_analysis.png)\n\n",
    "**What it shows:** A square matrix showing pairwise correlations between health indicators, with colors indicating strength and direction of relationship.\n\n",
    "**How to interpret:**\n",
    "- **Red/warm colors**: Positive correlation (variables increase together)\n",
    "- **Blue/cool colors**: Negative correlation (one increases, other decreases)\n",
    "- **White/near zero**: No correlation\n",
    "- **Values close to ±1**: Strong linear relationship\n\n",
    "**Key correlations to discuss:**\n",
    "- BMI with waist circumference (expected high correlation)\n",
    "- Systolic with diastolic blood pressure\n",
    "- HDL with total cholesterol (negative - protective effect)\n",
    "- Age with blood pressure and cholesterol\n",
    "- Depression scores with physical health indicators\n\n",
    "**Multicollinearity concerns:**\n",
    "Variables with |r| > 0.7 may cause issues in some analyses. GMM is generally robust to correlated features, but understanding correlations helps interpret cluster structure.\n\n",
    "**Presentation talking points:**\n",
    "\"The correlation analysis reveals expected relationships, such as the negative correlation between HDL and total cholesterol, reflecting the protective cardiovascular effects of HDL. The moderate correlation between BMI and blood pressure suggests metabolic pathways connecting obesity to hypertension.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value Analysis (03_missing_value_analysis.png)\n\n",
    "**What it shows:** A heatmap or bar chart displaying the extent and pattern of missing data across all variables.\n\n",
    "**How to interpret:**\n",
    "- **Percentage missing**: Variables with >5% missing may need special handling\n",
    "- **Pattern**: Random missing (MAR), completely random (MCAR), or non-random (MNAR)\n",
    "- **Correlation**: Variables missing together may be related (e.g., lab values)\n\n",
    "**Handling strategy justification:**\n",
    "- Mean/median imputation for continuous variables\n",
    "- Mode imputation for categorical variables\n",
    "- Consider sensitivity analysis with multiple imputation\n\n",
    "**Presentation talking points:**\n",
    "\"Missing data patterns were primarily Missing at Random (MAR), with laboratory variables showing the highest missingness due to fasting requirements. Imputation was performed using median values for continuous variables, preserving the central tendency of each distribution.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 5: Dimensionality Reduction Outputs\n\n",
    "#### PCA Scree Plot (04_pca_scree_plot.png)\n\n",
    "**What it shows:** A bar chart or line plot showing the variance explained by each principal component, often with a cumulative variance line.\n\n",
    "**How to interpret:**\n",
    "- **Elbow point**: Where adding more components yields diminishing returns\n",
    "- **80% threshold**: Number of components needed to explain 80% of variance\n",
    "- **Drop-off**: Sharp decrease indicates primary sources of variance\n\n",
    "**Typical findings in health data:**\n",
    "- First 2-3 components often capture metabolic syndrome patterns\n",
    "- Components may correspond to: body size, cardiovascular function, metabolic markers\n\n",
    "**Presentation talking points:**\n",
    "\"The scree plot demonstrates that the first 3-4 principal components capture the majority of variance in health indicators. This dimensionality reduction allows for effective 2D visualization while retaining the essential structural information.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA 2D Projection (05_pca_visualization.png)\n\n",
    "**What it shows:** Scatter plot of data points colored by cluster assignment, projected onto the first two principal components.\n\n",
    "**How to interpret:**\n",
    "- **Cluster separation**: How distinct the clusters appear in reduced space\n",
    "- **Overlap regions**: Areas where clusters merge (high uncertainty)\n",
    "- **Cluster shape**: Elliptical patterns reflect covariance structure\n",
    "- **Outliers**: Points far from cluster centers\n\n",
    "**What to look for:**\n",
    "- Clear separation indicates good clustering\n",
    "- Overlapping regions suggest need for more clusters or different approach\n",
    "- Linear arrangements may indicate dominant features\n\n",
    "**Presentation talking points:**\n",
    "\"The PCA projection shows clear separation between health phenotypes, with distinct clusters representing different metabolic risk profiles. The elliptical nature of clusters reflects the GMM's modeling of within-cluster covariance.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-SNE Visualization (06_tsne_visualization.png)\n\n",
    "**What it shows:** Non-linear projection of high-dimensional data onto 2D, preserving local neighborhood structure.\n\n",
    "**How to interpret:**\n",
    "- **Cluster tightness**: Compact clusters indicate consistent phenotypes\n",
    "- **Global structure**: Relative positions between clusters\n",
    "- **Noise**: Scattered points may be outliers or transitional cases\n",
    "- **Perplexity effects**: Different perplexity values may reveal different structures\n\n",
    "**Advantages over PCA:**\n",
    "- Can reveal non-linear relationships\n",
    "- Better at separating clusters visually\n",
    "- More faithful to local structure\n\n",
    "**Limitations:**\n",
    "- Not suitable for new data points (no transformation matrix)\n",
    "- Stochastic results (set random seed)\n",
    "- Cannot directly interpret component meanings\n\n",
    "**Presentation talking points:**\n",
    "\"The t-SNE visualization reveals non-linear structure in the health data that PCA may miss. The distinct clusters suggest that our GMM has successfully identified meaningful subpopulations with characteristic health profiles.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 6: Model Selection Outputs\n\n",
    "#### BIC/AIC Curves (07_bic_aic_plot.png)\n\n",
    "**What it shows:** Line plots of BIC and AIC values across different numbers of components (k), with the optimal k marked.\n\n",
    "**How to interpret:**\n",
    "- **Minimum point**: The k value with lowest BIC/AIC is optimal\n",
    "- **BIC vs AIC**: BIC typically selects fewer components (more conservative)\n",
    "- **Stability**: Flat regions indicate multiple good options\n",
    "- **Trend**: Should see U-shaped curve (decreasing then increasing)\n\n",
    "**Decision criteria:**\n",
    "- Primary: Minimum BIC (theoretical justification)\n",
    "- Secondary: Confirm with AIC\n",
    "- Tertiary: Consider interpretability of cluster count\n\n",
    "**Typical scenarios:**\n",
    "- Clear minimum: Good, select that k\n",
    "- Multiple minima: Choose simpler model\n",
    "- No minimum: May need to search wider range\n\n",
    "**Presentation talking points:**\n",
    "\"The BIC analysis identifies [optimal k] clusters as optimal, balancing model fit against complexity. The clear minimum in the BIC curve indicates that this number of components provides the best trade-off between explaining variance and avoiding overfitting.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 8: Cluster Profile Outputs\n\n",
    "#### Cluster Profile Heatmap (07_cluster_profiles_heatmap.png)\n\n",
    "**What it shows:** A heatmap displaying the mean values of each feature within each cluster, with z-score normalization for comparison.\n\n",
    "**How to interpret:**\n",
    "- **Colors**: Red = above population average, Blue = below average\n",
    "- **Rows**: Different features\n",
    "- **Columns**: Different clusters\n",
    "- **Patterns**: Clusters with similar color patterns share characteristics\n\n",
    "**Key questions to answer:**\n",
    "- Which cluster has highest cardiovascular risk?\n",
    "- Which cluster has best metabolic health?\n",
    "- Are there age-related patterns?\n",
    "- Do clusters differ by depression severity?\n\n",
    "**Clinical interpretation framework:**\n",
    "- **Cluster 1 (if exists)**: \"Healthy\" phenotype - low risk factors\n",
    "- **Cluster 2**: \"At-risk\" - elevated but not clinical\n",
    "- **Cluster 3**: \"Metabolic syndrome\" - multiple elevated risk factors\n",
    "- **Cluster 4 (if exists)**: Specific clinical phenotype\n\n",
    "**Presentation talking points:**\n",
    "\"The cluster profile heatmap reveals distinct health phenotypes. Cluster [X] shows elevated BMI and blood pressure, suggesting a cardiometabolic risk phenotype. Cluster [Y] demonstrates better metabolic profiles with lower glucose and cholesterol levels.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 15: Uncertainty Analysis Outputs\n\n",
    "#### Probability Distribution (08_uncertainty_analysis.png)\n\n",
    "**What it shows:** Four panels showing: (1) Histogram of max probabilities, (2) Pie chart of confidence levels, (3) Probability distributions by cluster, (4) Entropy distribution.\n\n",
    "**How to interpret:**\n",
    "- **High confidence (>80%)**: Points clearly belonging to one cluster\n",
    "- **Medium confidence (50-80%)**: Borderline cases\n",
    "- **Low confidence (<50%)**: Points in overlap regions\n",
    "- **Entropy**: Higher = more uncertain assignment\n\n",
    "**Quality thresholds:**\n",
    "- Good model: >70% high confidence\n",
    "- Acceptable: 50-70% high confidence\n",
    "- Poor: <50% high confidence\n\n",
    "**Clinical implications:**\n",
    "- High uncertainty patients may need additional clinical assessment\n",
    "- Could represent transitional health states\n",
    "- May warrant different clinical management\n\n",
    "**Presentation talking points:**\n",
    "\"The uncertainty analysis reveals that [X]% of individuals have high-confidence cluster assignments (probability >80%). The remaining [Y]% with lower confidence represent transitional cases or individuals with mixed health characteristics, requiring careful clinical interpretation.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 18: Cluster Distribution Outputs\n\n",
    "#### Cluster Size Pie Chart and Bar Chart (12_cluster_distribution.png)\n\n",
    "**What it shows:** (1) Pie chart showing proportion of population in each cluster, (2) Bar chart with counts and percentages.\n\n",
    "**How to interpret:**\n",
    "- **Unequal sizes**: Some phenotypes more common than others\n",
    "- **Dominant cluster**: Largest phenotype in population\n",
    "- **Rare phenotypes**: Small clusters may need more validation\n",
    "- **Balance**: Very unequal sizes may indicate sub-optimal k\n\n",
    "**Quality indicators:**\n",
    "- Reasonable sizes (10-50% each): Good cluster count\n",
    "- Very small clusters (<5%): May be noise or require more data\n",
    "- One dominant cluster (>80%): May need fewer clusters\n\n",
    "**Public health relevance:**\n",
    "- Cluster sizes indicate prevalence of each phenotype\n",
    "- Can inform resource allocation\n",
    "- Identify high-priority intervention targets\n\n",
    "**Presentation talking points:**\n",
    "\"The cluster distribution shows [X]% of the population in the low-risk phenotype, [Y]% in the moderate-risk group, and [Z]% in the high-risk category. This distribution provides important insights for public health planning and resource allocation.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 20: Final Summary Outputs\n\n",
    "#### Summary Dashboard (14_final_summary.png)\n\n",
    "**What it shows:** Four-panel summary with: (1) Cluster sizes, (2) Model performance metrics, (3) Confidence levels pie chart, (4) Key findings text box.\n\n",
    "**How to interpret:**\n",
    "- **Complete overview**: All key results in one figure\n",
    "- **Model quality**: Metrics indicate clustering effectiveness\n",
    "- **Certainty assessment**: Confidence distribution shows reliability\n",
    "- **Quick reference**: Key numbers for presentation\n\n",
    "**Key metrics to highlight:**\n",
    "- Number of clusters identified\n",
    "- Silhouette score (cluster quality)\n",
    "- Percentage high-confidence assignments\n",
    "- Total samples analyzed\n\n",
    "**Presentation talking points:**\n",
    "\"This final summary dashboard captures our key findings: [K] distinct health phenotypes were identified in [N] individuals, with a silhouette score of [S] indicating [good/moderate] cluster separation. The model achieves [X]% high-confidence assignments, demonstrating reliable phenotype classification.\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Performance Critique and Limitations\n\n",
    "### Strengths of the Current Approach\n\n",
    "**1. Probabilistic Framework**\n",
    "GMM provides soft clustering with probability estimates, which is more appropriate for health data where individuals rarely belong cleanly to discrete categories. This uncertainty quantification is valuable for clinical decision-making.\n\n",
    "**2. Flexible Covariance Structures**\n",
    "The ability to model different covariance types (full, tied, diagonal, spherical) allows the model to capture various cluster shapes, from spherical (like K-means) to highly elongated ellipsoids.\n\n",
    "**3. Rigorous Model Selection**\n",
    "Using both BIC and AIC for model selection provides theoretical grounding and cross-validation of the optimal number of clusters.\n\n",
    "**4. Comprehensive Validation**\n",
    "Multiple clustering quality metrics (Silhouette, Calinski-Harabasz, Davies-Bouldin) provide robust assessment of cluster quality.\n\n",
    "**5. Clinical Relevance**\n",
    "The analysis focuses on health phenotypes with direct clinical interpretation, linking statistical clusters to meaningful health categories.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations and Weaknesses\n\n",
    "**1. Assumption of Gaussian Distributions**\n",
    "GMM assumes that each cluster follows a multivariate normal distribution. Health data often exhibits non-Gaussian patterns (skewness, heavy tails, categorical variables). This assumption may be violated for:\n",
    "- Highly skewed variables (income, medical costs)\n",
    "- Bounded variables (percentages, rates)\n",
    "- Mixed continuous-categorical features\n\n",
    "**2. Sensitivity to Initialization**\n",
    "GMM uses random initialization, which can lead to different results across runs. The EM algorithm can get stuck in local optima, particularly with complex covariance structures.\n\n",
    "- *Mitigation in our work*: Used multiple initializations (n_init parameter)\n",
    "- *Still a concern*: May not find global optimum\n\n",
    "**3. Feature Selection Dependency**\n",
    "The clustering results depend heavily on which features are included. Relevant features may be omitted, while irrelevant features may introduce noise.\n\n",
    "- *Current approach*: Domain knowledge-based feature selection\n",
    "- *Limitation*: May miss important but non-obvious patterns\n",
    "- *Alternative*: Could use feature weighting or automatic relevance determination\n\n",
    "**4. Scalability Issues**\n",
    "The computational complexity of GMM is O(n × k × d² × iterations) for full covariance matrices. For very large datasets:\n",
    "- Full covariance may be computationally expensive\n",
    "- Memory requirements scale with d²\n\n",
    "**5. Interpretation Challenges**\n",
    "While we have cluster profiles, the meaning of each cluster requires careful clinical interpretation. Statistical clusters don't automatically translate to clinically meaningful phenotypes.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Performance Concerns\n\n",
    "#### Silhouette Score Interpretation\n\n",
    "| Score Range | Interpretation | Our Result |\n",
    "|-------------|----------------|------------|\n",
    "| 0.71 - 1.00 | Strong structure | Likely not achieved |\n",
    "| 0.51 - 0.70 | Moderate structure | Target range |\n",
    "| 0.26 - 0.50 | Weak structure | May indicate overlapping clusters |\n",
    "| ≤ 0.25 | No substantial structure | Problematic |\n\n",
    "**If silhouette < 0.5:**\n",
    "- Clusters may have significant overlap\n",
    "- Consider reducing k\n",
    "- Review feature selection\n",
    "- Consider alternative methods (spectral clustering, DBSCAN)\n\n",
    "#### Davies-Bouldin Index\n\n",
    "Lower is better (closer to 0 indicates better clustering).\n\n",
    "- DB < 1.0: Good cluster separation\n",
    "- DB 1.0 - 3.0: Moderate separation\n",
    "- DB > 3.0: Poor separation\n\n",
    "**If DB > 2.0:**\n",
    "- Clusters may be too similar\n",
    "- Consider feature engineering\n",
    "- Review if true subgroups exist in data\n\n",
    "#### High-Confidence Assignment Rate\n\n",
    "| High-Confidence Rate | Interpretation |\n",
    "|---------------------|----------------|\n",
    "| > 80% | Excellent certainty |\n",
    "| 60-80% | Good certainty |\n",
    "| 40-60% | Moderate overlap |\n",
    "| < 40% | Significant ambiguity |\n\n",
    "**If high-confidence rate < 60%:**\n",
    "- Many individuals are in overlap regions\n",
    "- Clusters may not be well-separated\n",
    "- Consider this a \"fuzzy\" clustering problem\n",
    "- May need clinical follow-up for ambiguous cases\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations for Improvement\n\n",
    "#### Short-Term Improvements\n\n",
    "**1. Alternative Initialization Methods**\n",
    "- Use k-means++ initialization instead of random\n",
    "- Initialize from K-means results\n",
    "- Use hierarchical clustering for initial centroids\n\n",
    "**2. Robust Covariance Estimation**\n",
    "- Apply regularization to covariance matrices\n",
    "- Use sparse GMM variants for high-dimensional data\n",
    "- Consider shrinkage estimators\n\n",
    "**3. Feature Engineering**\n",
    "- Create derived features (metabolic syndrome indicators)\n",
    "- Apply domain-specific transformations\n",
    "- Consider interaction terms\n\n",
    "**4. Validation Enhancement**\n",
    "- External validation with known clinical phenotypes\n",
    "- Temporal validation (if longitudinal data available)\n",
    "- Cross-validation for stability assessment\n\n",
    "#### Long-Term Improvements\n\n",
    "**1. Alternative Clustering Methods**\n",
    "- **Variational GMM**: Automatic relevance determination for feature selection\n",
    "- **Bayesian GMM**: Full posterior inference with uncertainty quantification\n",
    "- **Non-parametric methods**: Dirichlet Process GMM for automatic k selection\n",
    "- **Deep learning**: Variational autoencoders for complex patterns\n\n",
    "**2. Integration with Clinical Decision Support**\n",
    "- Develop risk stratification algorithms\n",
    "- Create phenotype-specific treatment recommendations\n",
    "- Build decision support tools for clinicians\n\n",
    "**3. Longitudinal Analysis**\n",
    "- Track phenotype transitions over time\n",
    "- Identify trajectory patterns\n",
    "- Predict future health outcomes\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical Evaluation Framework\n\n",
    "#### What Went Well\n\n",
    "1. **Systematic Model Selection**: The BIC/AIC approach provided a principled method for determining cluster count\n",
    "2. **Comprehensive Metrics**: Multiple evaluation metrics provided triangulated assessment\n",
    "3. **Clinical Interpretation**: Cluster profiles were linked to meaningful health characteristics\n",
    "4. **Uncertainty Quantification**: Probability-based assignments acknowledged clinical reality\n",
    "5. **Reproducibility**: Code structure and documentation enable replication\n\n",
    "#### What Could Be Improved\n\n",
    "1. **Feature Selection**: More systematic approach to feature importance and selection\n",
    "2. **Sensitivity Analysis**: Test robustness to different preprocessing choices\n",
    "3. **External Validation**: Compare with established clinical phenotypes\n",
    "4. **Computational Efficiency**: Optimize for larger datasets\n",
    "5. **Visual Communication**: Simplify visualizations for clinical audience\n\n",
    "#### Threats to Validity\n\n",
    "**Internal Validity**:\n",
    "- Confounding variables not controlled\n",
    "- Missing data handling may introduce bias\n",
    "- Imputation assumes data are MAR\n\n",
    "**External Validity**:\n",
    "- NHANES sample may not generalize to other populations\n",
    "- Cross-sectional data limits causal inference\n",
    "- Specific to US adult population\n\n",
    "**Construct Validity**:\n",
    "- Self-reported variables subject to recall bias\n",
    "- Laboratory values may have measurement error\n",
    "- Cluster assignment ≠ clinical diagnosis\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Presentation Tips and Common Questions\n\n",
    "### Anticipated Questions from Audience\n\n",
    "**Q: Why use GMM instead of K-means?**\n",
    "A: GMM provides probabilistic cluster assignments rather than hard assignments. This better reflects the reality that many individuals have characteristics of multiple health phenotypes. Additionally, GMM can model elliptical clusters with different shapes and orientations, capturing more complex patterns in health data.\n\n",
    "**Q: How did you determine the number of clusters?**\n",
    "A: We used both BIC and AIC criteria, which balance model fit against complexity. The optimal number of clusters was selected at the minimum of these curves. We also considered interpretability and clinical relevance of the resulting clusters.\n\n",
    "**Q: Are the clusters clinically meaningful?**\n",
    "A: The cluster profiles show distinct patterns in cardiovascular risk factors, metabolic markers, and mental health indicators. Each cluster can be characterized by a distinct health phenotype with specific risk factor profiles. However, clinical validation with known patient outcomes would strengthen this interpretation.\n\n",
    "**Q: What about the uncertainty in cluster assignments?**\n",
    "A: This is a key strength of GMM. We report that approximately [X]% of individuals have high-confidence assignments (>80% probability), while [Y]% have lower confidence. These borderline cases may represent individuals with mixed health characteristics or transitional states.\n\n",
    "**Q: Can this be used for clinical decision-making?**\n",
    "A: The current analysis is exploratory and identifies population phenotypes. For clinical use, the phenotypes would need validation with clinical outcomes, development of decision rules, and prospective testing. The probabilistic framework provides a foundation for risk stratification but requires further development.\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presentation Structure Recommendations\n\n",
    "#### Recommended Slide Flow\n\n",
    "**Slide 1: Title**\n",
    "- Project title, team members, course information\n\n",
    "**Slide 2: Problem Statement**\n",
    "- Health populations exhibit heterogeneity\n",
    "- Traditional methods miss nuanced subpopulations\n",
    "- Need probabilistic approaches for uncertainty\n\n",
    "**Slide 3: Methodology Overview**\n",
    "- NHANES dataset (5,000 samples, 47 features)\n",
    "- GMM approach with model selection\n",
    "- Validation framework\n\n",
    "**Slide 4: Data Overview**\n",
    "- Key variables and distributions\n",
    "- Missing data handling\n",
    "- Feature selection rationale\n\n",
    "**Slide 5: Model Selection**\n",
    "- BIC/AIC curves\n",
    "- Optimal k selection\n",
    "- Covariance type choice\n\n",
    "**Slide 6: Cluster Profiles**\n",
    "- Characterize each cluster\n",
    "- Clinical interpretation\n",
    "- Key distinguishing features\n\n",
    "**Slide 7: Visualizations**\n",
    "- PCA/t-SNE projections\n",
    "- Cluster separation quality\n",
    "- Uncertainty analysis\n\n",
    "**Slide 8: Model Performance**\n",
    "- Quality metrics table\n",
    "- High-confidence assignment rates\n",
    "- Comparison to benchmarks\n\n",
    "**Slide 9: Clinical Implications**\n",
    "- Phenotype characteristics\n",
    "- Public health relevance\n",
    "- Limitations and next steps\n\n",
    "**Slide 10: Conclusions**\n",
    "- Key findings summary\n",
    "- Contributions\n",
    "- Future work\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Talking Points for Each Section\n\n",
    "#### Introduction (2-3 minutes)\n\n",
    "- \"Health populations are not homogeneous - they exhibit natural heterogeneity\"\n",
    "- \"Traditional clustering forces hard assignments that may not reflect reality\"\n",
    "- \"GMM provides a probabilistic framework that captures this uncertainty\"\n",
    "- \"Our goal is to discover meaningful health phenotypes\"\n\n",
    "#### Methods (3-4 minutes)\n\n",
    "- \"We used NHANES data representing the US adult population\"\n",
    "- \"47 health indicators spanning demographics, biometrics, labs, and mental health\"\n",
    "- \"Systematic model selection using BIC/AIC criteria\"\n",
    "- \"Multiple validation metrics to assess cluster quality\"\n\n",
    "#### Results (5-6 minutes)\n\n",
    "- \"We identified [K] distinct health phenotypes\"\n",
    "- \"Present each cluster with key characteristics\"\n",
    "- \"Show visualization of cluster separation\"\n",
    "- \"Report uncertainty in assignments\"\n\n",
    "#### Discussion (3-4 minutes)\n\n",
    "- \"Clusters have clinical interpretation\"\n",
    "- \"Public health implications for each phenotype\"\n",
    "- \"Acknowledge limitations honestly\"\n",
    "- \"Propose next steps for validation\"\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Pitfalls to Avoid\n\n",
    "**1. Over-interpreting Small Differences**\n",
    "- Statistical significance ≠ clinical importance\n",
    "- Focus on substantial differences in cluster profiles\n\n",
    "**2. Ignoring Uncertainty**\n",
    "- Always mention high-confidence vs. low-confidence assignments\n",
    "- Acknowledge overlap regions\n\n",
    "**3. Causation Claims**\n",
    "- Clustering identifies associations, not causation\n",
    "- Avoid causal language unless specifically tested\n\n",
    "**4. Over-selling the Model**\n",
    "- Be honest about limitations\n",
    "- Acknowledge need for clinical validation\n\n",
    "**5. Technical Jargon**\n",
    "- Explain BIC, AIC, EM algorithm in accessible terms\n",
    "- Focus on clinical meaning, not mathematical details\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Quick Reference Tables\n\n",
    "### Model Hyperparameter Summary\n\n",
    "| Parameter | Description | Typical Values | Our Selection |\n",
    "|-----------|-------------|----------------|---------------|\n",
    "| n_components | Number of clusters | 2-10 | [To be filled] |\n",
    "| covariance_type | Cluster shape | full/tied/diag/spherical | [To be filled] |\n",
    "| n_init | Initializations | 1-10 | [To be filled] |\n",
    "| reg_covar | Regularization | 1e-6 to 1e-3 | [To be filled] |\n",
    "| max_iter | Max iterations | 100-500 | [To be filled] |\n",
    "| random_state | Random seed | Any integer | [To be filled] |\n\n",
    "### Performance Metrics Summary\n\n",
    "| Metric | Range | Interpretation | Our Result |\n",
    "|--------|-------|----------------|------------|\n",
    "| BIC | Any (lower better) | Model selection | [To be filled] |\n",
    "| AIC | Any (lower better) | Model selection | [To be filled] |\n",
    "| Silhouette | -1 to 1 (higher better) | Cluster quality | [To be filled] |\n",
    "| Calinski-Harabasz | >0 (higher better) | Cluster separation | [To be filled] |\n",
    "| Davies-Bouldin | >0 (lower better) | Cluster similarity | [To be filled] |\n\n",
    "### Cluster Characteristics Summary\n\n",
    "| Cluster | Size | % of Pop | Key Characteristics |\n",
    "|---------|------|----------|---------------------|\n",
    "| Cluster 0 | [X] | [Y]% | [Description] |\n",
    "| Cluster 1 | [X] | [Y]% | [Description] |\n",
    "| Cluster 2 | [X] | [Y]% | [Description] |\n",
    "| ... | ... | ... | ... |\n\n",
    "---\n\n",
    "*Document prepared for MSc Public Health Data Science - Advanced Machine Learning*\n",
    "*University of Nairobi - January 2025*\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}