#!/usr/bin/env python3
"""
Script to update GMM Health Phenotype Discovery notebook with comprehensive Phases 15-21.
"""

import json

# Read the notebook
with open('GMM_Health_Phenotype_Discovery.ipynb', 'r') as f:
    notebook = json.load(f)

# Find the cell index after Phase 14 ends
# Phase 14 ends with cluster quality metrics code cell
phase14_end_index = None
for i, cell in enumerate(notebook['cells']):
    if cell['cell_type'] == 'code':
        source = ''.join(cell['source'])
        if 'cluster_quality_metrics.csv' in source and 'print("=" * 70)' in source:
            phase14_end_index = i
            break

print(f"Found Phase 14 end at index: {phase14_end_index}")

# New phases content
new_cells = [
    # Phase 15 markdown
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 15: Uncertainty Analysis - Probability Distributions\n",
            "\n",
            "This section analyzes the uncertainty in GMM cluster assignments by examining probability distributions, confidence levels, and assignment entropy.\n"
        ]
    },
    # Phase 15 code
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# =============================================================================\n",
            "# PHASE 15: UNCERTAINTY ANALYSIS - PROBABILITY DISTRIBUTIONS\n",
            "# =============================================================================\n",
            "\n",
            "print(\"=\" * 70)\n",
            "print(\"UNCERTAINTY ANALYSIS: CLUSTER ASSIGNMENT PROBABILITIES\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "# Get membership probabilities from the optimal GMM model\n",
            "membership_probs = gmm_optimal.predict_proba(X_scaled)\n",
            "\n",
            "# Analyze certainty levels across all samples\n",
            "max_probs = membership_probs.max(axis=1)\n",
            "high_conf = (max_probs >= 0.8).sum()\n",
            "med_conf = ((max_probs >= 0.5) & (max_probs < 0.8)).sum()\n",
            "low_conf = ((max_probs >= 0.3) & (max_probs < 0.5)).sum()\n",
            "very_low_conf = (max_probs < 0.3).sum()\n",
            "\n",
            "print(\"\\n[INFO] Cluster Assignment Certainty Distribution:\")\n",
            "print(f\"  High Confidence (>=80%):     {high_conf:,} ({100*high_conf/len(max_probs):.1f}%)\")\n",
            "print(f\"  Medium Confidence (50-80%):  {med_conf:,} ({100*med_conf/len(max_probs):.1f}%)\")\n",
            "print(f\"  Low Confidence (30-50%):     {low_conf:,} ({100*low_conf/len(max_probs):.1f}%)\")\n",
            "print(f\"  Very Low Confidence (<30%):  {very_low_conf:,} ({100*very_low_conf/len(max_probs):.1f}%)\")\n",
            "\n",
            "# Calculate assignment entropy for each sample\n",
            "entropy = -np.sum(membership_probs * np.log(membership_probs + 1e-10), axis=1)\n",
            "print(f\"\\n[INFO] Assignment Entropy Statistics:\")\n",
            "print(f\"  Mean Entropy:   {entropy.mean():.4f}\")\n",
            "print(f\"  Std Entropy:    {entropy.std():.4f}\")\n",
            "print(f\"  Min Entropy:    {entropy.min():.4f}\")\n",
            "print(f\"  Max Entropy:    {entropy.max():.4f}\")\n",
            "\n",
            "# Create comprehensive uncertainty visualization\n",
            "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
            "fig.suptitle('GMM Cluster Assignment Uncertainty Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
            "\n",
            "# Subplot 1: Distribution of maximum probabilities with threshold lines\n",
            "axes[0, 0].hist(max_probs, bins=50, color='steelblue', edgecolor='white', alpha=0.7)\n",
            "axes[0, 0].axvline(x=0.8, color='green', linestyle='--', linewidth=2, label='High confidence (0.8)')\n",
            "axes[0, 0].axvline(x=0.5, color='orange', linestyle='--', linewidth=2, label='Medium confidence (0.5)')\n",
            "axes[0, 0].axvline(x=0.3, color='red', linestyle='--', linewidth=2, label='Low confidence (0.3)')\n",
            "axes[0, 0].set_xlabel('Maximum Cluster Probability', fontsize=12)\n",
            "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
            "axes[0, 0].set_title('Distribution of Cluster Assignment Certainty', fontweight='bold')\n",
            "axes[0, 0].legend(fontsize=10)\n",
            "axes[0, 0].grid(True, alpha=0.3)\n",
            "\n",
            "# Subplot 2: Certainty categories pie chart\n",
            "certainty_counts = [high_conf, med_conf, low_conf, very_low_conf]\n",
            "certainty_labels = ['High (>=80%)', 'Medium (50-80%)', 'Low (30-50%)', 'Very Low (<30%)']\n",
            "colors = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c']\n",
            "explode = (0.05, 0, 0, 0)\n",
            "\n",
            "wedges, texts, autotexts = axes[0, 1].pie(certainty_counts, labels=certainty_labels, autopct='%1.1f%%',\n",
            "                                         colors=colors, explode=explode, shadow=True, startangle=90)\n",
            "axes[0, 1].set_title('Cluster Assignment Certainty Categories', fontweight='bold')\n",
            "\n",
            "# Subplot 3: Probability distributions by cluster (overlapping histograms)\n",
            "for i in range(best_params['n_components']):\n",
            "    axes[1, 0].hist(membership_probs[:, i], bins=30, alpha=0.5, label=f'Cluster {i}', edgecolor='white')\n",
            "axes[1, 0].set_xlabel('Membership Probability', fontsize=12)\n",
            "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
            "axes[1, 0].set_title('Probability Distribution by Cluster', fontweight='bold')\n",
            "axes[1, 0].legend(fontsize=10)\n",
            "axes[1, 0].grid(True, alpha=0.3)\n",
            "\n",
            "# Subplot 4: Entropy distribution histogram\n",
            "axes[1, 1].hist(entropy, bins=50, color='purple', edgecolor='white', alpha=0.7)\n",
            "axes[1, 1].axvline(x=entropy.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean ({entropy.mean():.3f})')\n",
            "axes[1, 1].set_xlabel('Assignment Entropy', fontsize=12)\n",
            "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
            "axes[1, 1].set_title('Distribution of Assignment Entropy\\n(Lower = More Certain)', fontweight='bold')\n",
            "axes[1, 1].legend(fontsize=10)\n",
            "axes[1, 1].grid(True, alpha=0.3)\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(os.path.join(FIGURES_DIR, 'plots', '08_uncertainty_analysis.png'), dpi=150, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "# Save uncertainty metrics to CSV\n",
            "uncertainty_df = pd.DataFrame({\n",
            "    'respondent_id': range(len(data)),\n",
            "    'cluster': data['cluster'],\n",
            "    'max_probability': max_probs,\n",
            "    'entropy': entropy\n",
            "})\n",
            "\n",
            "# Add probability columns for each cluster\n",
            "for i in range(best_params['n_components']):\n",
            "    uncertainty_df[f'cluster_{i}_probability'] = membership_probs[:, i]\n",
            "\n",
            "uncertainty_df.to_csv(os.path.join(OUTPUT_DIR, 'metrics', 'uncertainty_analysis.csv'), index=False)\n",
            "\n",
            "print(f\"\\n[OK] Figure saved: {os.path.join(FIGURES_DIR, 'plots', '08_uncertainty_analysis.png')}\")\n",
            "print(f\"[OK] Analysis saved: {os.path.join(OUTPUT_DIR, 'metrics', 'uncertainty_analysis.csv')}\")\n",
            "print(\"=\" * 70)\n"
        ]
    },
    # Phase 16 markdown
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 16: Feature Distribution by Cluster\n",
            "\n",
            "This section visualizes the distribution of key health features within each cluster using box plots and violin plots.\n"
        ]
    },
    # Phase 16 code
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# =============================================================================\n",
            "# PHASE 16: FEATURE DISTRIBUTION BY CLUSTER\n",
            "# =============================================================================\n",
            "\n",
            "print(\"=\" * 70)\n",
            "print(\"FEATURE DISTRIBUTION BY CLUSTER\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "import seaborn as sns\n",
            "\n",
            "# Features to plot\n",
            "plot_features = ['age', 'bmi', 'systolic_bp_mmHg', 'fasting_glucose_mg_dL', 'phq9_total_score']\n",
            "plot_titles = ['Age (years)', 'BMI (kg/m\\u00b2)', 'Systolic BP (mmHg)', 'Fasting Glucose (mg/dL)', 'PHQ-9 Score']\n",
            "\n",
            "# Create box plots\n",
            "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
            "axes = axes.flatten()\n",
            "\n",
            "for idx, (feature, title) in enumerate(zip(plot_features, plot_titles)):\n",
            "    sns.boxplot(data=data, x='cluster', y=feature, ax=axes[idx], palette='Set2')\n",
            "    axes[idx].set_title(f'{title} by Cluster', fontsize=12, fontweight='bold')\n",
            "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
            "\n",
            "axes[5].axis('off')\n",
            "plt.tight_layout()\n",
            "plt.savefig(os.path.join(FIGURES_DIR, 'plots', '09_feature_boxplots.png'), dpi=150, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print(f\"\\n[OK] Figure saved: {os.path.join(FIGURES_DIR, 'plots', '09_feature_boxplots.png')}\")\n",
            "\n",
            "# Create violin plots\n",
            "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
            "axes = axes.flatten()\n",
            "\n",
            "for idx, (feature, title) in enumerate(zip(plot_features, plot_titles)):\n",
            "    sns.violinplot(data=data, x='cluster', y=feature, ax=axes[idx], palette='Set2', inner='box')\n",
            "    axes[idx].set_title(f'{title} Distribution by Cluster', fontsize=12, fontweight='bold')\n",
            "    axes[idx].grid(True, alpha=0.3, axis='y')\n",
            "\n",
            "axes[5].axis('off')\n",
            "plt.tight_layout()\n",
            "plt.savefig(os.path.join(FIGURES_DIR, 'plots', '10_feature_violin.png'), dpi=150, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "print(f\"[OK] Figure saved: {os.path.join(FIGURES_DIR, 'plots', '10_feature_violin.png')}\")\n",
            "print(\"=\" * 70)\n"
        ]
    },
    # Phase 17 markdown
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 17: Probability Uncertainty Visualization\n",
            "\n",
            "This section provides detailed visualizations of cluster assignment confidence, including box plots by cluster and probability heatmaps.\n"
        ]
    },
    # Phase 17 code
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# =============================================================================\n",
            "# PHASE 17: PROBABILITY UNCERTAINTY VISUALIZATION\n",
            "# =============================================================================\n",
            "\n",
            "print(\"=\" * 70)\n",
            "print(\"PROBABILITY UNCERTAINTY VISUALIZATION\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "# Get maximum probability for each sample from membership probabilities\n",
            "max_probs = membership_probs.max(axis=1)\n",
            "data['max_probability'] = max_probs\n",
            "\n",
            "# Categorize confidence into three levels\n",
            "high_conf = (max_probs >= 0.8).sum()\n",
            "mod_conf = ((max_probs >= 0.5) & (max_probs < 0.8)).sum()\n",
            "low_conf = (max_probs < 0.5).sum()\n",
            "\n",
            "print(f\"\\n[INFO] Confidence Level Summary:\")\n",
            "print(f\"  High Confidence (>=0.8): {high_conf:,} ({100*high_conf/len(data):.1f}%)\")\n",
            "print(f\"  Moderate Confidence (0.5-0.8): {mod_conf:,} ({100*mod_conf/len(data):.1f}%)\")\n",
            "print(f\"  Low Confidence (<0.5): {low_conf:,} ({100*low_conf/len(data):.1f}%)\")\n",
            "\n",
            "# Create comprehensive visualizations\n",
            "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
            "fig.suptitle('GMM Probability Uncertainty Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
            "\n",
            "# Subplot 1: Histogram of maximum probabilities\n",
            "axes[0, 0].hist(max_probs, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
            "axes[0, 0].axvline(x=0.8, color='green', linestyle='--', linewidth=2, label='High (0.8)')\n",
            "axes[0, 0].axvline(x=0.5, color='orange', linestyle='--', linewidth=2, label='Moderate (0.5)')\n",
            "axes[0, 0].set_xlabel('Maximum Assignment Probability', fontsize=12)\n",
            "axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
            "axes[0, 0].set_title('Distribution of Assignment Confidence', fontsize=14, fontweight='bold')\n",
            "axes[0, 0].legend(fontsize=10)\n",
            "axes[0, 0].grid(True, alpha=0.3)\n",
            "\n",
            "# Subplot 2: Pie chart of confidence levels\n",
            "confidence_counts = [high_conf, mod_conf, low_conf]\n",
            "confidence_labels = [f'High\\n(n={high_conf:,})', f'Moderate\\n(n={mod_conf:,})', f'Low\\n(n={low_conf:,})']\n",
            "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
            "axes[0, 1].pie(confidence_counts, labels=confidence_labels, autopct='%1.1f%%',\n",
            "               colors=colors, explode=[0.02, 0.02, 0.05], shadow=True, startangle=90)\n",
            "axes[0, 1].set_title('Confidence Level Distribution', fontsize=14, fontweight='bold')\n",
            "\n",
            "# Subplot 3: Box plot of confidence by cluster\n",
            "cluster_prob_data = [data[data['cluster'] == c]['max_probability'].values for c in sorted(data['cluster'].unique())]\n",
            "bp = axes[1, 0].boxplot(cluster_prob_data, labels=[f'Cluster {c}' for c in sorted(data['cluster'].unique())],\n",
            "                        patch_artist=True)\n",
            "for patch, color in zip(bp['boxes'], plt.cm.Set2(np.linspace(0, 1, len(cluster_prob_data)))):\n",
            "    patch.set_facecolor(color)\n",
            "axes[1, 0].set_xlabel('Cluster', fontsize=12)\n",
            "axes[1, 0].set_ylabel('Maximum Probability', fontsize=12)\n",
            "axes[1, 0].set_title('Assignment Confidence by Cluster', fontsize=14, fontweight='bold')\n",
            "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
            "\n",
            "# Subplot 4: Cluster probability heatmap\n",
            "prob_means = membership_probs.mean(axis=0)\n",
            "im = axes[1, 1].imshow(prob_means.T, aspect='auto', cmap='YlOrRd')\n",
            "axes[1, 1].set_xlabel('Sample Index (sorted)', fontsize=12)\n",
            "axes[1, 1].set_ylabel('Cluster', fontsize=12)\n",
            "axes[1, 1].set_title('Cluster Probability Heatmap', fontsize=14, fontweight='bold')\n",
            "axes[1, 1].set_yticks(range(len(prob_means)))\n",
            "axes[1, 1].set_yticklabels([f'Cluster {i}' for i in range(len(prob_means))])\n",
            "plt.colorbar(im, ax=axes[1, 1], label='Mean Probability')\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(os.path.join(FIGURES_DIR, 'plots', '11_probability_uncertainty.png'), dpi=150, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "# Save detailed confidence metrics\n",
            "confidence_df = pd.DataFrame({\n",
            "    'respondent_id': range(len(data)),\n",
            "    'cluster': data['cluster'],\n",
            "    'max_probability': max_probs,\n",
            "    'confidence_category': pd.cut(max_probs, bins=[0, 0.5, 0.8, 1.0],\n",
            "                                  labels=['Low', 'Moderate', 'High'])\n",
            "})\n",
            "confidence_df.to_csv(os.path.join(OUTPUT_DIR, 'metrics', 'confidence_analysis.csv'), index=False)\n",
            "\n",
            "print(f\"\\n[OK] Figure saved: {os.path.join(FIGURES_DIR, 'plots', '11_probability_uncertainty.png')}\")\n",
            "print(f\"[OK] Analysis saved: {os.path.join(OUTPUT_DIR, 'metrics', 'confidence_analysis.csv')}\")\n",
            "print(\"=\" * 70)\n"
        ]
    },
    # Phase 18 markdown
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 18: Cluster Size and Proportion Analysis\n",
            "\n",
            "This section analyzes the distribution of samples across clusters.\n"
        ]
    },
    # Phase 18 code
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# =============================================================================\n",
            "# PHASE 18: CLUSTER SIZE AND PROPORTION ANALYSIS\n",
            "# =============================================================================\n",
            "\n",
            "print(\"=\" * 70)\n",
            "print(\"CLUSTER SIZE AND PROPORTION ANALYSIS\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "# Calculate cluster sizes and proportions\n",
            "cluster_sizes = data['cluster'].value_counts().sort_index()\n",
            "cluster_proportions = (cluster_sizes / len(data)) * 100\n",
            "\n",
            "print(\"\\n[INFO] Cluster Distribution:\")\n",
            "print(\"-\" * 50)\n",
            "print(f\"{'Cluster':<10} {'Count':<12} {'Proportion':<15}\")\n",
            "print(\"-\" * 50)\n",
            "for cluster in cluster_sizes.index:\n",
            "    print(f\"{cluster:<10} {cluster_sizes[cluster]:<12,} {cluster_proportions[cluster]:.2f}%\")\n",
            "print(\"-\" * 50)\n",
            "print(f\"{'Total':<10} {len(data):<12,} {100.0:.2f}%\")\n",
            "\n",
            "# Create visualizations\n",
            "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
            "fig.suptitle('Cluster Size Distribution Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
            "\n",
            "# Pie chart\n",
            "colors = plt.cm.Set2(np.linspace(0, 1, len(cluster_sizes)))\n",
            "axes[0].pie(cluster_sizes, labels=[f'Cluster {i}\\n(n={v:,})' for i, v in cluster_sizes.items()],\n",
            "            autopct='%1.1f%%', colors=colors, explode=[0.02]*len(cluster_sizes),\n",
            "            shadow=True, startangle=90)\n",
            "axes[0].set_title('Cluster Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
            "\n",
            "# Bar chart\n",
            "bars = axes[1].bar(cluster_sizes.index, cluster_sizes.values, color=colors, edgecolor='black', alpha=0.8)\n",
            "axes[1].set_xlabel('Cluster', fontsize=12)\n",
            "axes[1].set_ylabel('Number of Individuals', fontsize=12)\n",
            "axes[1].set_title('Cluster Size Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
            "axes[1].set_xticks(cluster_sizes.index)\n",
            "axes[1].grid(True, alpha=0.3, axis='y')\n",
            "\n",
            "for bar, count in zip(bars, cluster_sizes.values):\n",
            "    height = bar.get_height()\n",
            "    axes[1].annotate(f'{count:,}\\n({count/len(data)*100:.1f}%)',\n",
            "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
            "                    xytext=(0, 3), textcoords=\"offset points\",\n",
            "                    ha='center', va='bottom', fontsize=10)\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(os.path.join(FIGURES_DIR, 'plots', '12_cluster_distribution.png'), dpi=150, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "# Save cluster distribution data\n",
            "distribution_df = pd.DataFrame({\n",
            "    'cluster': cluster_sizes.index,\n",
            "    'count': cluster_sizes.values,\n",
            "    'proportion': cluster_proportions.values\n",
            "})\n",
            "distribution_df.to_csv(os.path.join(OUTPUT_DIR, 'metrics', 'cluster_distribution.csv'), index=False)\n",
            "\n",
            "print(f\"\\n[OK] Figure saved: {os.path.join(FIGURES_DIR, 'plots', '12_cluster_distribution.png')}\")\n",
            "print(f\"[OK] Distribution saved: {os.path.join(OUTPUT_DIR, 'metrics', 'cluster_distribution.csv')}\")\n",
            "print(\"=\" * 70)\n"
        ]
    },
    # Phase 19 markdown
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 19: Demographics and Cluster Association\n",
            "\n",
            "This section analyzes the relationship between demographic variables and cluster membership.\n"
        ]
    },
    # Phase 19 code
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# =============================================================================\n",
            "# PHASE 19: DEMOGRAPHICS AND CLUSTER ASSOCIATION\n",
            "# =============================================================================\n",
            "\n",
            "print(\"=\" * 70)\n",
            "print(\"DEMOGRAPHICS AND CLUSTER ASSOCIATION\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "from scipy.stats import chi2_contingency\n",
            "\n",
            "demographic_vars = ['gender', 'race/ethnicity', 'age_group']\n",
            "demographic_names = ['Gender', 'Race/Ethnicity', 'Age Group']\n",
            "\n",
            "print(\"\\n[INFO] Chi-Square Tests for Demographics:\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "chi2_results = {}\n",
            "for var, name in zip(demographic_vars, demographic_names):\n",
            "    if var in data.columns:\n",
            "        contingency_table = pd.crosstab(data[var], data['cluster'])\n",
            "        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
            "        chi2_results[name] = {'chi2': chi2, 'p_value': p_value, 'dof': dof}\n",
            "        print(f\"\\n{name}:\")\n",
            "        print(f\"  Chi-square statistic: {chi2:.4f}\")\n",
            "        print(f\"  P-value: {p_value:.6f}\")\n",
            "        print(f\"  Significant (p<0.05): {'Yes' if p_value < 0.05 else 'No'}\")\n",
            "\n",
            "# Create visualizations\n",
            "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
            "fig.suptitle('Demographic Analysis by Cluster', fontsize=16, fontweight='bold', y=1.02)\n",
            "\n",
            "if 'gender' in data.columns:\n",
            "    gender_cluster = pd.crosstab(data['gender'], data['cluster'], normalize='index') * 100\n",
            "    gender_cluster.plot(kind='bar', ax=axes[0, 0], colormap='Set2', edgecolor='black')\n",
            "    axes[0, 0].set_title('Cluster Distribution by Gender', fontsize=14, fontweight='bold')\n",
            "    axes[0, 0].tick_params(axis='x', rotation=0)\n",
            "    axes[0, 0].set_ylabel('Percentage (%)')\n",
            "    axes[0, 0].legend(title='Cluster', fontsize=10)\n",
            "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
            "\n",
            "if 'age_group' in data.columns:\n",
            "    age_cluster = pd.crosstab(data['age_group'], data['cluster'], normalize='index') * 100\n",
            "    age_cluster.plot(kind='bar', ax=axes[0, 1], colormap='Set2', edgecolor='black')\n",
            "    axes[0, 1].set_title('Cluster Distribution by Age Group', fontsize=14, fontweight='bold')\n",
            "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
            "    axes[0, 1].set_ylabel('Percentage (%)')\n",
            "    axes[0, 1].legend(title='Cluster', fontsize=10)\n",
            "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
            "\n",
            "if 'race/ethnicity' in data.columns:\n",
            "    race_cluster = pd.crosstab(data['cluster'], data['race/ethnicity'], normalize='index') * 100\n",
            "    race_cluster.plot(kind='barh', stacked=True, ax=axes[1, 0], colormap='Set2', edgecolor='black')\n",
            "    axes[1, 0].set_title('Race/Ethnicity by Cluster', fontsize=14, fontweight='bold')\n",
            "    axes[1, 0].set_xlabel('Percentage (%)')\n",
            "    axes[1, 0].legend(title='Race/Ethnicity', fontsize=8, loc='lower right')\n",
            "    axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
            "\n",
            "# Age distribution by cluster\n",
            "for cluster in sorted(data['cluster'].unique()):\n",
            "    cluster_ages = data[data['cluster'] == cluster]['age']\n",
            "    axes[1, 1].hist(cluster_ages, bins=20, alpha=0.5, label=f'Cluster {cluster}', edgecolor='black')\n",
            "axes[1, 1].set_title('Age Distribution by Cluster', fontsize=14, fontweight='bold')\n",
            "axes[1, 1].set_xlabel('Age (years)', fontsize=12)\n",
            "axes[1, 1].set_ylabel('Frequency', fontsize=12)\n",
            "axes[1, 1].legend(fontsize=10)\n",
            "axes[1, 1].grid(True, alpha=0.3)\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.savefig(os.path.join(FIGURES_DIR, 'plots', '13_demographic_analysis.png'), dpi=150, bbox_inches='tight')\n",
            "plt.show()\n",
            "\n",
            "# Save chi-square results\n",
            "chi2_df = pd.DataFrame(chi2_results).T\n",
            "chi2_df.to_csv(os.path.join(OUTPUT_DIR, 'metrics', 'chi_square_results.csv'))\n",
            "\n",
            "print(f\"\\n[OK] Figure saved: {os.path.join(FIGURES_DIR, 'plots', '13_demographic_analysis.png')}\")\n",
            "print(f\"[OK] Chi-square results saved: {os.path.join(OUTPUT_DIR, 'metrics', 'chi_square_results.csv')}\")\n",
            "print(\"=\" * 70)\n"
        ]
    },
    # Phase 20 markdown
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 20: Final Summary and Export\n",
            "\n",
            "This section provides a comprehensive summary of the GMM clustering analysis and exports all results.\n"
        ]
    },
    # Phase 20 code
    {
        "cell_type": "code",
        "execution_count": None,
        "metadata": {},
        "outputs": [],
        "source": [
            "# =============================================================================\n",
            "# PHASE 20: FINAL SUMMARY AND EXPORT\n",
            "# =============================================================================\n",
            "\n",
            "print(\"=\" * 70)\n",
            "print(\"FINAL SUMMARY AND EXPORT\")\n",
            "print(\"=\" * 70)\n",
            "\n",
            "# Complete summary statistics\n",
            "print(\"\\n\" + \"-\" * 70)\n",
            "print(\"COMPLETE PROJECT SUMMARY\")\n",
            "print(\"-\" * 70)\n",
            "\n",
            "print(f\"\\n[DATASET CHARACTERISTICS]\")\n",
            "print(f\"  Total Samples: {len(data):,}\")\n",
            "print(f\"  Features Used: {len(FEATURE_COLUMNS)}\")\n",
            "\n",
            "print(f\"\\n[MODEL CONFIGURATION]\")\n",
            "print(f\"  Algorithm: Gaussian Mixture Models (GMM)\")\n",
            "print(f\"  Number of Components: {best_params['n_components']}\")\n",
            "print(f\"  Covariance Type: {best_params['covariance_type']}\")\n",
            "print(f\"  Number of Initializations: {best_params['n_init']}\")\n",
            "\n",
            "print(f\"\\n[MODEL PERFORMANCE]\")\n",
            "print(f\"  BIC Score: {full_eval['bic']:.2f}\")\n",
            "print(f\"  AIC Score: {full_eval['aic']:.2f}\")\n",
            "print(f\"  Silhouette Score: {full_eval['silhouette']:.4f}\")\n",
            "\n",
            "print(f\"\\n[CLUSTER SUMMARY]\")\n",
            "n_clusters = best_params['n_components']\n",
            "for c in range(n_clusters):\n",
            "    cluster_subset = data[data['cluster'] == c]\n",
            "    print(f\"  Cluster {c} ({len(cluster_subset):,} individuals, {100*len(cluster_subset)/len(data):.1f}%):\")\n",
            "    print(f\"    Mean Age: {cluster_subset['age'].mean():.1f} years\")\n",
            "    print(f\"    Mean BMI: {cluster_subset['bmi'].mean():.1f}\")\n",
            "    print(f\"    Mean Systolic BP: {cluster_subset['systolic_bp_mmHg'].mean():.1f} mmHg\")\n",
            "\n",
            "print(f\"\\n[UNCERTAINTY ANALYSIS]\")\n",
            "print(f\"  High Confidence (>=0.8): {high_conf:,} ({100*high_conf/len(data):.1f}%)\")\n",
            "print(f\"  Moderate Confidence: {mod_conf:,} ({100*mod_conf/len(data):.1f}%)\")\n",
            "print(f\"  Low Confidence (<0.5): {low_conf:,} ({100*low_conf/len(data):.1f}%)\")\n",
            "print(f\"  Mean Assignment Entropy: {entropy.mean():.4f}\")\n",
            "\n",
            "# Export all results\n",
            "print(\"\\n[INFO] Exporting results...\")\n",
            "\n",
            "# Save complete dataset with cluster assignments\n",
            "export_df = data.copy()\n",
            "export_df['max_probability'] = max_probs\n",
            "export_df['entropy'] = entropy\n",
            "export_df.to_csv(os.path.join(OUTPUT_DIR, 'predictions', 'complete_cluster_assignments.csv'), index=False)\n",
            "print(\"  [OK] Complete cluster assignments saved\")\n",
            "\n",
            "# Save cluster profiles\n",
            "cluster_profiles_export = cluster_profiles.copy()\n",
            "cluster_profiles_export['n_individuals'] = cluster_sizes.values\n",
            "cluster_profiles_export['proportion'] = cluster_proportions.values\n",
            "cluster_profiles_export.to_csv(os.path.join(OUTPUT_DIR, 'cluster_profiles', 'detailed_cluster_profiles.csv'))\n",
            "print(\"  [OK] Detailed cluster profiles saved\")\n",
            "\n",
            "# Save probability assignments\n",
            "prob_df = pd.DataFrame(membership_probs, columns=[f'Cluster_{i}_Prob' for i in range(n_clusters)])\n",
            "prob_df['Predicted_Cluster'] = data['cluster'].values\n",
            "prob_df['Max_Probability'] = max_probs\n",
            "prob_df['Entropy'] = entropy\n",
            "prob_df.to_csv(os.path.join(OUTPUT_DIR, 'predictions', 'cluster_probabilities.csv'), index=False)\n",
            "print(\"  [OK] Cluster probabilities saved\")\n",
            "\n",
            "# Save model using the save_model function\n",
            "model_filepath = save_model(gmm_optimal, 'final_gmm_model', subdir='final')\n",
            "print(f\"  [OK] Final model saved to: {model_filepath}\")\n",
            "\n",
            "print(\"\\n\" + \"=\" * 70)\n",
            "print(\"ANALYSIS COMPLETE\")\n",
            "print(\"=\" * 70)\n",
            "print(f\"\\nAll results saved to: {OUTPUT_DIR}\")\n",
            "print(f\"Figures saved to: {os.path.join(FIGURES_DIR, 'plots')}\")\n",
            "print(f\"Models saved to: {MODELS_DIR}\")\n",
            "print(\"=\" * 70)\n"
        ]
    },
    # Phase 21 References
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Phase 21: References\n",
            "\n",
            "1. McLachlan, G. J., & Peel, D. (2000). Finite Mixture Models. John Wiley & Sons.\n",
            "\n",
            "2. Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics.\n",
            "\n",
            "3. Pedregosa, F., et al. (2011). Scikit-learn: Machine Learning in Python. JMLR 12, 2825-2830.\n",
            "\n",
            "4. NHANES Documentation - National Center for Health Statistics, CDC.\n"
        ]
    }
]

# Replace cells from phase14_end_index + 1 to end with new cells
notebook['cells'] = notebook['cells'][:phase14_end_index + 1] + new_cells

# Write the updated notebook
with open('GMM_Health_Phenotype_Discovery.ipynb', 'w') as f:
    json.dump(notebook, f, indent=1)

print(f"Notebook updated successfully!")
print(f"Added {len(new_cells)} new cells (Phases 15-21)")
